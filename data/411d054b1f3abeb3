==== SOURCE 

https://www.the-scientist.com/news-opinion/ai-decodes-speech-and-hearing-based-on-brain-activity-66213

==== AGENT

Funded by Facebook and carried out at the University of California, San Francisco (UCSF)


==== GOAL

Facebook would ultimately like to build a non-invasive gadget that could convert a person’s imagined speech directly to text, with no typing required.

==== DATA

The study was conducted on three people who had arrays of electrodes temporarily implanted in their brains to monitor their brain activity in preparation for surgery for epilepsy.

==== METHODS

They trained with a limited set of questions and answers and used a computer model to decode what the participant heard based on their brain activity.


==== RESULTS

A computer model used in the study was able to correctly decode the question a participant heard 76 percent of the time, and the answer that person gave 61 percent of the time, based on the participants’ brain activity, Moses and his colleagues report. Listening and speaking produced activity in different brain regions.


==== COMMENTS

Very small sample size and an invasive method was reported to be used but Facebook plan on researching this for many more years and do not expect any major advancement for ten years or so. If sucessful it will be ground breaking.
