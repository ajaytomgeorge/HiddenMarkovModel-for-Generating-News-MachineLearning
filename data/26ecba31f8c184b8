==== SOURCE

https://medium.com/@anidaro/how-snapchats-filters-work-86973c3e2e9f

==== AGENT

Snapchat with initial facial detection and "lenses" (More commonly known as filters) made by Looksery, a Ukrainian app, which snapchat bought over and continue to improve currently.

==== GOAL

To produce Augemented Reality lenses in their consumer base for use in advertisements and entertainment.

==== DATA

Point masks are generated by people physically picking points on a lot of pictures of peoples faces. These point-masks, and random faces without point masks are the two main data sources in Snapchat's machine learning process.

==== METHODS

Snapchat use a very intelligent way for looking for faces in an image called the Viola-Jones algorithm. The algorithm constantly scans the picture for contrasts in shades of each pixel. These shades will show typical highlights of a persons face and project a point mask into the real world. The point mask is then smoothened bu joining up points on the point mask. This makes a web-like face structure and brings certain features into proportion for use in the Augmented Reality lense stage. The data is fed in at approximately 24 frames per second.

==== RESULTS

The result is a data driven model that constantly readjusts the points on your face at every frame capture.

==== COMMENTS

This story could have explained more about the Deep Learning aspect of the Viola-Jones algorithm. In my opinion, the story explained mroe about the computer vision side of things, which is fair considering the title of the article.

