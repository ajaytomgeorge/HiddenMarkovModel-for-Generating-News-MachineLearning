==== SOURCE

http://news.mit.edu/2019/faster-video-recognition-smartphone-era-1011

==== AGENT

MIT-IBM Watson AI Lab

==== GOAL

Train a video-recognition model using less computing resources than existing alternatives.

==== DATA

The 20BN-SOMETHING-SOMETHING dataset, a large collection of densely-labeled video clips that show humans performing pre-defined basic actions with everyday objects

==== METHODS

Han and his colleagues designed an operation they call a temporal shift module which shifts the feature maps of a selected video frame to its neighboring frames. By mingling spatial representations of the past, present, and future, the model gets a sense of time passing without explicitly representing it. 

==== RESULTS

The model won first place at classifying the something-something dataset in recent public rankings.

==== COMMENTS

The research described looks promising, no qualms about the article.

